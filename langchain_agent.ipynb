{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPysca+QVKtjS6K3hnTkPDj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abaloch/langchainllm/blob/main/langchain_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-L5JfdptFK-",
        "outputId": "3dd4ede9-eca7-4415-c824-6ae4261f5b13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.0-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-0.2.1-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting tavily-python\n",
            "  Downloading tavily_python-0.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting langgraph-checkpoint-sqlite\n",
            "  Downloading langgraph_checkpoint_sqlite-1.0.3-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.34)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.10.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting langchain<0.4.0,>=0.3.0 (from langchain-community)\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-core<0.4.0,>=0.3.0 (from langchain-community)\n",
            "  Downloading langchain_core-0.3.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.112 (from langchain-community)\n",
            "  Downloading langsmith-0.1.121-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.26.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-community)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-1.0.10-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting anthropic<1,>=0.30.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.34.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (0.7.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.10/dist-packages (from langchain-anthropic) (2.9.1)\n",
            "Collecting tiktoken>=0.5.1 (from tavily-python)\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting httpx (from tavily-python)\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting aiosqlite<0.21.0,>=0.20.0 (from langgraph-checkpoint-sqlite)\n",
            "  Downloading aiosqlite-0.20.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiosqlite<0.21.0,>=0.20.0->langgraph-checkpoint-sqlite) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.7.0)\n",
            "Collecting jiter<1,>=0.4.0 (from anthropic<1,>=0.30.0->langchain-anthropic)\n",
            "  Downloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: tokenizers>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from anthropic<1,>=0.30.0->langchain-anthropic) (0.19.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx->tavily-python)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->tavily-python) (3.8)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->tavily-python)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain<0.4.0,>=0.3.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.0->langchain-community)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain-community) (24.1)\n",
            "Collecting msgpack<2.0.0,>=1.1.0 (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph)\n",
            "  Downloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.112->langchain-community)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m906.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.23.3)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.5.1->tavily-python) (2024.5.15)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.30.0->langchain-anthropic) (1.2.2)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain-community)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (0.24.7)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (3.16.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (2024.6.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.0->anthropic<1,>=0.30.0->langchain-anthropic) (4.66.5)\n",
            "Downloading langchain_community-0.3.0-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.2.1-py3-none-any.whl (21 kB)\n",
            "Downloading tavily_python-0.5.0-py3-none-any.whl (14 kB)\n",
            "Downloading langgraph_checkpoint_sqlite-1.0.3-py3-none-any.whl (12 kB)\n",
            "Downloading aiosqlite-0.20.0-py3-none-any.whl (15 kB)\n",
            "Downloading anthropic-0.34.2-py3-none-any.whl (891 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m891.9/891.9 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.1-py3-none-any.whl (405 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m405.1/405.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.121-py3-none-any.whl (289 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
            "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jiter-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
            "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading msgpack-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (378 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m378.0/378.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: tenacity, python-dotenv, orjson, mypy-extensions, msgpack, marshmallow, jsonpointer, jiter, h11, aiosqlite, typing-inspect, tiktoken, jsonpatch, httpcore, pydantic-settings, httpx, dataclasses-json, tavily-python, langsmith, anthropic, langchain-core, langgraph-checkpoint, langchain-text-splitters, langchain-anthropic, langgraph-checkpoint-sqlite, langgraph, langchain, langchain-community\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: msgpack\n",
            "    Found existing installation: msgpack 1.0.8\n",
            "    Uninstalling msgpack-1.0.8:\n",
            "      Successfully uninstalled msgpack-1.0.8\n",
            "Successfully installed aiosqlite-0.20.0 anthropic-0.34.2 dataclasses-json-0.6.7 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 jiter-0.5.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.0 langchain-anthropic-0.2.1 langchain-community-0.3.0 langchain-core-0.3.1 langchain-text-splitters-0.3.0 langgraph-0.2.22 langgraph-checkpoint-1.0.10 langgraph-checkpoint-sqlite-1.0.3 langsmith-0.1.121 marshmallow-3.22.0 msgpack-1.1.0 mypy-extensions-1.0.0 orjson-3.10.7 pydantic-settings-2.5.2 python-dotenv-1.0.1 tavily-python-0.5.0 tenacity-8.5.0 tiktoken-0.7.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "%pip install -U langchain-community langgraph langchain-anthropic tavily-python langgraph-checkpoint-sqlite"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1x15FQcRtPJc",
        "outputId": "d413cd8b-bf61-4b38-df2e-0d00dbfba74c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"TAVILY_API_KEY\"] = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72olbeeWtUZI",
        "outputId": "4a3c7cfd-7b19-4487-9f60-692aaf37780f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.tools.tavily_search import TavilySearchResults\n",
        "\n",
        "search = TavilySearchResults(max_results=2)\n",
        "search_results = search.invoke(\"what is the weather in SF\")\n",
        "print(search_results)\n",
        "# If we want, we can create other tools.\n",
        "# Once we have all the tools we want, we can put them in a list that we will reference later.\n",
        "tools = [search]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6UBWKQvtjO3",
        "outputId": "a1022f91-bfe5-47d1-a1ad-c5e0b448a773"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1726623581, 'localtime': '2024-09-17 18:39'}, 'current': {'last_updated_epoch': 1726623000, 'last_updated': '2024-09-17 18:30', 'temp_c': 16.7, 'temp_f': 62.1, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 9.6, 'wind_kph': 15.5, 'wind_degree': 267, 'wind_dir': 'W', 'pressure_mb': 1016.0, 'pressure_in': 29.99, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 78, 'cloud': 100, 'feelslike_c': 16.7, 'feelslike_f': 62.1, 'windchill_c': 12.5, 'windchill_f': 54.5, 'heatindex_c': 13.7, 'heatindex_f': 56.7, 'dewpoint_c': 12.3, 'dewpoint_f': 54.1, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 3.0, 'gust_mph': 13.1, 'gust_kph': 21.1}}\"}, {'url': 'https://www.meteoprog.com/weather/Sanfrancisco/month/september/', 'content': 'San Francisco (United States) weather in September 2024 ☀️ Accurate weather forecast for San Francisco in September ⛅ Detailed forecast By month Current temperature \"near me\" Weather news ⊳ Widget of weather ⊳ Water temperature | METEOPROG'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -qU langchain-anthropic"
      ],
      "metadata": {
        "id": "LxCBn1gqy1tk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"ANTHROPIC_API_KEY\"] = getpass.getpass()\n",
        "\n",
        "from langchain_anthropic import ChatAnthropic\n",
        "\n",
        "model = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6CQsM0Uy6i9",
        "outputId": "a1c5695d-348c-4e48-96a3-a68be75ca020"
      },
      "execution_count": 13,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "response = model.invoke([HumanMessage(content=\"hi!\")])\n",
        "response.content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Lxj6Rco-zCi6",
        "outputId": "4aa1708b-3d1c-417a-d53b-4d54b8d8efd1"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello! How can I assist you today? Feel free to ask any questions or let me know if you need help with anything.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_with_tools = model.bind_tools(tools)"
      ],
      "metadata": {
        "id": "yYqeJwkezGK8"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"Hi!\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCcv1dM4zOJI",
        "outputId": "18dd4531-2faa-456e-b9fa-a485430b9c61"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: Hello! Welcome to our conversation. How can I assist you today? Is there any specific information you're looking for or any questions you'd like to ask?\n",
            "ToolCalls: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model_with_tools.invoke([HumanMessage(content=\"What's the weather in SF?\")])\n",
        "\n",
        "print(f\"ContentString: {response.content}\")\n",
        "print(f\"ToolCalls: {response.tool_calls}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPlMM2cnzcyn",
        "outputId": "d7f4b7a3-46a7-453c-8715-0187efa764e5"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ContentString: [{'text': \"I apologize, but I don't have a specific tool available to check the current weather in San Francisco. However, I can use a search tool to find the most up-to-date weather information for you. Let me do that now.\", 'type': 'text'}, {'id': 'toolu_01Cwjzusu4exxxT7be98QdKf', 'input': {'query': 'current weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}]\n",
            "ToolCalls: [{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'toolu_01Cwjzusu4exxxT7be98QdKf', 'type': 'tool_call'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.prebuilt import create_react_agent\n",
        "\n",
        "agent_executor = create_react_agent(model, tools)"
      ],
      "metadata": {
        "id": "EQIIJQ_vzklT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"hi!\")]})\n",
        "\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zcEPTPzLzpd0",
        "outputId": "9b2d0364-303a-42a1-b3f6-7c2f03427739"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='hi!', additional_kwargs={}, response_metadata={}, id='02c189c0-8759-4115-8997-93d75bea28a5'),\n",
              " AIMessage(content=\"Hello! It's nice to meet you. How can I assist you today? I'm here to help with any questions you might have or tasks you need assistance with. Is there anything specific you'd like to know or discuss?\", additional_kwargs={}, response_metadata={'id': 'msg_01DkHx6ByRk54mXhdYdkuKmK', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 399, 'output_tokens': 49}}, id='run-74d4f3f3-cedf-4597-8b5b-e77955eb48c2-0', usage_metadata={'input_tokens': 399, 'output_tokens': 49, 'total_tokens': 448})]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = agent_executor.invoke(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        ")\n",
        "response[\"messages\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPHjC00HzxPL",
        "outputId": "e739d146-4246-41fe-872d-70353031830c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[HumanMessage(content='whats the weather in sf?', additional_kwargs={}, response_metadata={}, id='27a44105-b466-4d05-966f-8ab619ca776b'),\n",
              " AIMessage(content=[{'text': \"I apologize, but I don't have direct access to real-time weather information. However, I can help you find the current weather in San Francisco using a search tool. Let me do that for you.\", 'type': 'text'}, {'id': 'toolu_01NcFuC2fJSicR9gFb22pLgN', 'input': {'query': 'current weather in San Francisco'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}], additional_kwargs={}, response_metadata={'id': 'msg_01Mjkpx9W7DnjZSByo4U3H8z', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 404, 'output_tokens': 106}}, id='run-90c3c2c7-39eb-40e0-b068-5066916ef4f0-0', tool_calls=[{'name': 'tavily_search_results_json', 'args': {'query': 'current weather in San Francisco'}, 'id': 'toolu_01NcFuC2fJSicR9gFb22pLgN', 'type': 'tool_call'}], usage_metadata={'input_tokens': 404, 'output_tokens': 106, 'total_tokens': 510}),\n",
              " ToolMessage(content='[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\'location\\': {\\'name\\': \\'San Francisco\\', \\'region\\': \\'California\\', \\'country\\': \\'United States of America\\', \\'lat\\': 37.78, \\'lon\\': -122.42, \\'tz_id\\': \\'America/Los_Angeles\\', \\'localtime_epoch\\': 1726623995, \\'localtime\\': \\'2024-09-17 18:46\\'}, \\'current\\': {\\'last_updated_epoch\\': 1726623900, \\'last_updated\\': \\'2024-09-17 18:45\\', \\'temp_c\\': 16.7, \\'temp_f\\': 62.1, \\'is_day\\': 1, \\'condition\\': {\\'text\\': \\'Overcast\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/day/122.png\\', \\'code\\': 1009}, \\'wind_mph\\': 9.6, \\'wind_kph\\': 15.5, \\'wind_degree\\': 267, \\'wind_dir\\': \\'W\\', \\'pressure_mb\\': 1016.0, \\'pressure_in\\': 29.99, \\'precip_mm\\': 0.0, \\'precip_in\\': 0.0, \\'humidity\\': 78, \\'cloud\\': 100, \\'feelslike_c\\': 16.7, \\'feelslike_f\\': 62.1, \\'windchill_c\\': 12.5, \\'windchill_f\\': 54.5, \\'heatindex_c\\': 13.7, \\'heatindex_f\\': 56.7, \\'dewpoint_c\\': 12.3, \\'dewpoint_f\\': 54.1, \\'vis_km\\': 16.0, \\'vis_miles\\': 9.0, \\'uv\\': 3.0, \\'gust_mph\\': 13.1, \\'gust_kph\\': 21.1}}\"}, {\"url\": \"https://forecast.weather.gov/MapClick.php?lon=-122.43573&lat=37.68754\", \"content\": \"Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 61°F. 16°C. Humidity: 78%: ... 2024-6pm PDT Sep 18, 2024 . ... Hourly Weather Forecast. National Digital Forecast Database. High Temperature. Chance of Precipitation. ACTIVE ALERTS Toggle menu. Warnings By State; Excessive Rainfall;\"}]', name='tavily_search_results_json', id='f0a997c3-6ec5-492a-9362-56bc3b2f9c3f', tool_call_id='toolu_01NcFuC2fJSicR9gFb22pLgN', artifact={'query': 'current weather in San Francisco', 'follow_up_questions': None, 'answer': None, 'images': [], 'results': [{'title': 'Weather in San Francisco', 'url': 'https://www.weatherapi.com/', 'content': \"{'location': {'name': 'San Francisco', 'region': 'California', 'country': 'United States of America', 'lat': 37.78, 'lon': -122.42, 'tz_id': 'America/Los_Angeles', 'localtime_epoch': 1726623995, 'localtime': '2024-09-17 18:46'}, 'current': {'last_updated_epoch': 1726623900, 'last_updated': '2024-09-17 18:45', 'temp_c': 16.7, 'temp_f': 62.1, 'is_day': 1, 'condition': {'text': 'Overcast', 'icon': '//cdn.weatherapi.com/weather/64x64/day/122.png', 'code': 1009}, 'wind_mph': 9.6, 'wind_kph': 15.5, 'wind_degree': 267, 'wind_dir': 'W', 'pressure_mb': 1016.0, 'pressure_in': 29.99, 'precip_mm': 0.0, 'precip_in': 0.0, 'humidity': 78, 'cloud': 100, 'feelslike_c': 16.7, 'feelslike_f': 62.1, 'windchill_c': 12.5, 'windchill_f': 54.5, 'heatindex_c': 13.7, 'heatindex_f': 56.7, 'dewpoint_c': 12.3, 'dewpoint_f': 54.1, 'vis_km': 16.0, 'vis_miles': 9.0, 'uv': 3.0, 'gust_mph': 13.1, 'gust_kph': 21.1}}\", 'score': 0.9999642, 'raw_content': None}, {'title': 'National Weather Service', 'url': 'https://forecast.weather.gov/MapClick.php?lon=-122.43573&lat=37.68754', 'content': 'Current conditions at SAN FRANCISCO DOWNTOWN (SFOC1) Lat: 37.77056°NLon: 122.42694°WElev: 150.0ft. NA. 61°F. 16°C. Humidity: 78%: ... 2024-6pm PDT Sep 18, 2024 . ... Hourly Weather Forecast. National Digital Forecast Database. High Temperature. Chance of Precipitation. ACTIVE ALERTS Toggle menu. Warnings By State; Excessive Rainfall;', 'score': 0.99801224, 'raw_content': None}], 'response_time': 2.69}),\n",
              " AIMessage(content=\"Based on the search results, I can provide you with the current weather information for San Francisco. Here's a summary:\\n\\nAs of September 17, 2024, at around 6:45 PM local time:\\n\\n1. Temperature: 62.1°F (16.7°C)\\n2. Condition: Overcast\\n3. Humidity: 78%\\n4. Wind: 9.6 mph (15.5 km/h), coming from the West\\n5. Precipitation: 0 inches (0 mm)\\n6. Visibility: 9 miles (16 km)\\n7. UV Index: 3.0 (moderate)\\n\\nThe weather is described as overcast, which means the sky is mostly or completely covered by clouds. The temperature feels comfortable, but you might want to bring a light jacket if you're planning to be outside, especially considering the wind.\\n\\nKeep in mind that weather conditions can change rapidly, so it's always a good idea to check for updates if you're planning activities based on the weather.\", additional_kwargs={}, response_metadata={'id': 'msg_016wNJc7um6Zi2Su9eU72piJ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 1167, 'output_tokens': 234}}, id='run-de19503d-4d2b-4441-93e6-1508b2977edd-0', usage_metadata={'input_tokens': 1167, 'output_tokens': 234, 'total_tokens': 1401})]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06YVelG8z_ze",
        "outputId": "ea1326f4-a3b2-4c1f-f5be-779f83b08a8c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"I apologize, but I don't have access to real-time weather information for San Francisco or any other location. The tools available to me don't include a weather service. However, I can search for recent weather information about San Francisco using the search function. Would you like me to do that?\", additional_kwargs={}, response_metadata={'id': 'msg_014ujADciHU7NEnDeLzQvij3', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 404, 'output_tokens': 64}}, id='run-0f1f57aa-5225-4e54-a01a-3049c23b717c-0', usage_metadata={'input_tokens': 404, 'output_tokens': 64, 'total_tokens': 468})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "async for event in agent_executor.astream_events(\n",
        "    {\"messages\": [HumanMessage(content=\"whats the weather in sf?\")]}, version=\"v1\"\n",
        "):\n",
        "    kind = event[\"event\"]\n",
        "    if kind == \"on_chain_start\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print(\n",
        "                f\"Starting agent: {event['name']} with input: {event['data'].get('input')}\"\n",
        "            )\n",
        "    elif kind == \"on_chain_end\":\n",
        "        if (\n",
        "            event[\"name\"] == \"Agent\"\n",
        "        ):  # Was assigned when creating the agent with `.with_config({\"run_name\": \"Agent\"})`\n",
        "            print()\n",
        "            print(\"--\")\n",
        "            print(\n",
        "                f\"Done agent: {event['name']} with output: {event['data'].get('output')['output']}\"\n",
        "            )\n",
        "    if kind == \"on_chat_model_stream\":\n",
        "        content = event[\"data\"][\"chunk\"].content\n",
        "        if content:\n",
        "            # Empty content in the context of OpenAI means\n",
        "            # that the model is asking for a tool to be invoked.\n",
        "            # So we only print non-empty content\n",
        "            print(content, end=\"|\")\n",
        "    elif kind == \"on_tool_start\":\n",
        "        print(\"--\")\n",
        "        print(\n",
        "            f\"Starting tool: {event['name']} with inputs: {event['data'].get('input')}\"\n",
        "        )\n",
        "    elif kind == \"on_tool_end\":\n",
        "        print(f\"Done tool: {event['name']}\")\n",
        "        print(f\"Tool output was: {event['data'].get('output')}\")\n",
        "        print(\"--\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xa0o_qAB0HCw",
        "outputId": "0d737774-5844-4396-a0d4-7c60a16e3fa8"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'text': 'I', 'type': 'text', 'index': 0}]|[{'text': ' apolog', 'type': 'text', 'index': 0}]|[{'text': 'ize, but I don', 'type': 'text', 'index': 0}]|[{'text': \"'t have\", 'type': 'text', 'index': 0}]|[{'text': ' a', 'type': 'text', 'index': 0}]|[{'text': ' specific', 'type': 'text', 'index': 0}]|[{'text': ' tool available', 'type': 'text', 'index': 0}]|[{'text': ' to check', 'type': 'text', 'index': 0}]|[{'text': ' the current', 'type': 'text', 'index': 0}]|[{'text': ' weather in', 'type': 'text', 'index': 0}]|[{'text': ' San Francisco. However', 'type': 'text', 'index': 0}]|[{'text': ', I', 'type': 'text', 'index': 0}]|[{'text': ' can use', 'type': 'text', 'index': 0}]|[{'text': ' the search', 'type': 'text', 'index': 0}]|[{'text': ' function', 'type': 'text', 'index': 0}]|[{'text': ' to find recent', 'type': 'text', 'index': 0}]|[{'text': ' weather information', 'type': 'text', 'index': 0}]|[{'text': ' for you', 'type': 'text', 'index': 0}]|[{'text': '.', 'type': 'text', 'index': 0}]|[{'text': ' Woul', 'type': 'text', 'index': 0}]|[{'text': 'd you like me to search', 'type': 'text', 'index': 0}]|[{'text': ' for the current weather in', 'type': 'text', 'index': 0}]|[{'text': ' San Francisco?', 'type': 'text', 'index': 0}]|"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "memory = MemorySaver()"
      ],
      "metadata": {
        "id": "x5E_6tGD0OTn"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent_executor = create_react_agent(model, tools, checkpointer=memory)\n",
        "\n",
        "config = {\"configurable\": {\"thread_id\": \"abc123\"}}"
      ],
      "metadata": {
        "id": "D8arl6-z0STl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"hi im bob!\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rL9dGTqF0Uqo",
        "outputId": "d7ddf9b1-2e58-45c0-d6a7-2ab606d98dc3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"Hello Bob! It's nice to meet you. How can I assist you today? Is there anything specific you'd like to know or discuss?\", additional_kwargs={}, response_metadata={'id': 'msg_01MiBmckYoy11pUrDxdjKo7P', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 401, 'output_tokens': 32}}, id='run-70de1b0a-726c-47c8-bc92-796ae25158d2-0', usage_metadata={'input_tokens': 401, 'output_tokens': 32, 'total_tokens': 433})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGrwgj4G0Xud",
        "outputId": "73a664d7-d923-48c9-e487-8e39e058fbcc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content='Your name is Bob. You introduced yourself as \"bob\" in your first message.', additional_kwargs={}, response_metadata={'id': 'msg_01KbxLYE8L74MYhXtTbjZfQZ', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 441, 'output_tokens': 20}}, id='run-3838fbd9-cb49-4fad-b5d5-0918ac965cb6-0', usage_metadata={'input_tokens': 441, 'output_tokens': 20, 'total_tokens': 461})]}}\n",
            "----\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"xyz123\"}}\n",
        "for chunk in agent_executor.stream(\n",
        "    {\"messages\": [HumanMessage(content=\"whats my name?\")]}, config\n",
        "):\n",
        "    print(chunk)\n",
        "    print(\"----\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncIUT09_0cVy",
        "outputId": "008f76fe-36c3-4b8e-e9cf-ce6abe256116"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'agent': {'messages': [AIMessage(content=\"I apologize, but I don't have access to personal information about individual users. As an AI assistant, I don't have any way to know your name unless you tell me. Is there something else I can help you with?\", additional_kwargs={}, response_metadata={'id': 'msg_01Y5bmxjEhVskkbwokycDDuz', 'model': 'claude-3-5-sonnet-20240620', 'stop_reason': 'end_turn', 'stop_sequence': None, 'usage': {'input_tokens': 402, 'output_tokens': 50}}, id='run-761c96a6-a5d5-4b55-8ec3-1200788352f5-0', usage_metadata={'input_tokens': 402, 'output_tokens': 50, 'total_tokens': 452})]}}\n",
            "----\n"
          ]
        }
      ]
    }
  ]
}